{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNLyHl2gH03FUPfOigewRje"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sZFc1SA66Gve","executionInfo":{"status":"ok","timestamp":1730266431182,"user_tz":-330,"elapsed":572,"user":{"displayName":"Gayatri Imbrapure","userId":"16247426128552499599"}},"outputId":"89ffbfa4-6ce5-4011-bdd1-38a40f1f292f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing dot-product.cu\n"]}],"source":["%%writefile dot-product.cu\n","#include <stdio.h>\n","#include <stdlib.h>\n","#include <cuda.h>\n","#include <cuda_runtime.h>\n","#include <time.h>\n","\n","#define THREADS_PER_BLOCK 256\n","\n","// CUDA Kernel for Dot Product using Atomic Operations\n","__global__ void dotProductCUDA(float *A, float *B, float *result, int N) {\n","    __shared__ float cache[THREADS_PER_BLOCK];\n","    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n","    int cacheIdx = threadIdx.x;\n","    float tempSum = 0;\n","\n","    // Compute partial dot product for this block\n","    while (tid < N) {\n","        tempSum += A[tid] * B[tid];\n","        tid += blockDim.x * gridDim.x;\n","    }\n","\n","    // Store the partial result in shared memory\n","    cache[cacheIdx] = tempSum;\n","\n","    // Synchronize threads in this block\n","    __syncthreads();\n","\n","    // Perform reduction in shared memory\n","    int i = blockDim.x / 2;\n","    while (i != 0) {\n","        if (cacheIdx < i) {\n","            cache[cacheIdx] += cache[cacheIdx + i];\n","        }\n","        __syncthreads();\n","        i /= 2;\n","    }\n","\n","    // Store the result from this block to global memory\n","    if (cacheIdx == 0) atomicAdd(result, cache[0]);\n","}\n","\n","// CPU-based Dot Product\n","float dotProductCPU(float *A, float *B, int N) {\n","    float sum = 0;\n","    for (int i = 0; i < N; i++) {\n","        sum += A[i] * B[i];\n","    }\n","    return sum;\n","}\n","\n","// Helper function to initialize vector with random values\n","void initializeVector(float *vector, int size) {\n","    for (int i = 0; i < size; i++) {\n","        vector[i] = (float)rand() / RAND_MAX;\n","    }\n","}\n","\n","// Helper function to get current time in seconds\n","double getTime() {\n","    struct timespec ts;\n","    clock_gettime(CLOCK_REALTIME, &ts);\n","    return ts.tv_sec + ts.tv_nsec * 1e-9;\n","}\n","\n","int main() {\n","    int N = 1000000; // Vector size (can be adjusted)\n","\n","    // Allocate host memory\n","    float *h_A = (float *)malloc(N * sizeof(float));\n","    float *h_B = (float *)malloc(N * sizeof(float));\n","    float h_resultCPU, h_resultGPU;\n","\n","    // Initialize vectors A and B with random values\n","    initializeVector(h_A, N);\n","    initializeVector(h_B, N);\n","\n","    // CPU Dot Product\n","    double startCPU = getTime();\n","    h_resultCPU = dotProductCPU(h_A, h_B, N);\n","    double endCPU = getTime();\n","    double cpuTime = endCPU - startCPU;\n","\n","    // Allocate device memory\n","    float *d_A, *d_B, *d_result;\n","    cudaMalloc((void **)&d_A, N * sizeof(float));\n","    cudaMalloc((void **)&d_B, N * sizeof(float));\n","    cudaMalloc((void **)&d_result, sizeof(float));\n","\n","    // Copy data from host to device\n","    cudaMemcpy(d_A, h_A, N * sizeof(float), cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_B, h_B, N * sizeof(float), cudaMemcpyHostToDevice);\n","    cudaMemset(d_result, 0, sizeof(float));\n","\n","    // Define grid and block dimensions\n","    int blocksPerGrid = (N + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;\n","\n","    // Set up CUDA events for accurate GPU timing\n","    cudaEvent_t start, stop;\n","    cudaEventCreate(&start);\n","    cudaEventCreate(&stop);\n","\n","    // Start recording time for GPU\n","    cudaEventRecord(start);\n","    dotProductCUDA<<<blocksPerGrid, THREADS_PER_BLOCK>>>(d_A, d_B, d_result, N);\n","    cudaEventRecord(stop);\n","\n","    // Wait for the kernel to complete\n","    cudaEventSynchronize(stop);\n","\n","    // Calculate GPU execution time\n","    float gpuTime = 0;\n","    cudaEventElapsedTime(&gpuTime, start, stop);\n","    gpuTime /= 1000;  // Convert from milliseconds to seconds\n","\n","    // Copy result back to host\n","    cudaMemcpy(&h_resultGPU, d_result, sizeof(float), cudaMemcpyDeviceToHost);\n","\n","    // Calculate speedup\n","    double speedup = cpuTime / gpuTime;\n","\n","    // Output results\n","    printf(\"CPU Result: %f\\n\", h_resultCPU);\n","    printf(\"GPU Result: %f\\n\", h_resultGPU);\n","    printf(\"CPU Execution Time: %f seconds\\n\", cpuTime);\n","    printf(\"GPU Execution Time: %f seconds\\n\", gpuTime);\n","    printf(\"Speedup: %f\\n\", speedup);\n","\n","    // Free device memory\n","    cudaFree(d_A);\n","    cudaFree(d_B);\n","    cudaFree(d_result);\n","\n","    // Free host memory\n","    free(h_A);\n","    free(h_B);\n","\n","    // Destroy CUDA events\n","    cudaEventDestroy(start);\n","    cudaEventDestroy(stop);\n","\n","    return 0;\n","}\n"]},{"cell_type":"code","source":["!nvcc dot-product.cu -o dot-product"],"metadata":{"id":"h-Oz_kXN6UZp","executionInfo":{"status":"ok","timestamp":1730266483109,"user_tz":-330,"elapsed":3453,"user":{"displayName":"Gayatri Imbrapure","userId":"16247426128552499599"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!./dot-product"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OXsp7iXP6Y7W","executionInfo":{"status":"ok","timestamp":1730266486956,"user_tz":-330,"elapsed":523,"user":{"displayName":"Gayatri Imbrapure","userId":"16247426128552499599"}},"outputId":"b5b19cb4-1528-4fff-b1cc-5f333f31253a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU Result: 249863.093750\n","GPU Result: 249902.562500\n","CPU Execution Time: 0.003804 seconds\n","GPU Execution Time: 0.114311 seconds\n","Speedup: 0.033280\n"]}]}]}